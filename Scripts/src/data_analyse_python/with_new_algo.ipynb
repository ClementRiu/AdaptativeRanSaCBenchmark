{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "little-protection",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_loader import All_Data_Loader\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "labeled-contribution",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_path = \"/home/riuclement/Documents/RANSAC-benchmark/3dv_experiment/general/homography/2021_06_22_09_28_43/\"\n",
    "# default_path = \"/home/riuclement/Documents/RANSAC-benchmark/3dv_experiment/general/homography/2021_07_08_12_47_32/\"\n",
    "# default_path = \"/home/riuclement/Documents/RANSAC-benchmark/3dv_experiment/general/fundamental/2021_06_23_09_30_12/\"\n",
    "default_path = \"/home/riuclement/Documents/RANSAC-benchmark/3dv_experiment/general/fundamental/2021_07_07_18_24_09/\"\n",
    "# default_path = \"/home/riuclement/Documents/RANSAC-benchmark/3dv_experiment/general/fundamental/2021_07_09_07_36_56/\"\n",
    "# default_path = \"/home/riuclement/Documents/RANSAC-benchmark/3dv_experiment/general/essential/2021_06_13_11_25_09/\"\n",
    "\n",
    "# other_editable_glob_to_results = [\n",
    "#     default_path + \"experiment_results/{}/hom_{}_std*_ratio*_output.txt\",\n",
    "#     default_path + \"experiment_results/{}/hom_{}_std*_ratio*_magsacOut.txt\",    \n",
    "# ]\n",
    "# magsac_default_path = default_path + \"experiment_results/uniform/hom_{}_std*_ratio*_magsac{}.txt\"\n",
    "\n",
    "\n",
    "other_editable_glob_to_results = [\n",
    "    default_path + \"experiment_results/{}/fun_{}_std*_ratio*_output.txt\",\n",
    "    default_path + \"experiment_results/{}/fun_{}_std*_ratio*_magsacOut.txt\",    \n",
    "]\n",
    "magsac_default_path = default_path + \"experiment_results/uniform/fun_{}_std*_ratio*_magsac{}.txt\"\n",
    "\n",
    "# other_editable_glob_to_results = [\n",
    "#     default_path + \"experiment_results/{}/ess_{}_std*_ratio*_output.txt\",\n",
    "#     default_path + \"experiment_results/{}/ess_{}_std*_ratio*_magsacOut.txt\",    \n",
    "# ]\n",
    "# magsac_default_path = default_path + \"experiment_results/uniform/ess_{}_std*_ratio*_magsac{}.txt\"\n",
    "\n",
    "# other_editable_glob_to_results = [\n",
    "#     \"/home/clementriu/Documents/these/RANSAC-benchmark/merged_script/experience_data/\" + \\\n",
    "# \"remote_fundamental/magsac-test/experience_results/{}/fun_{}_std*_ratio*_output.txt\",\n",
    "#     \"/home/clementriu/Documents/these/RANSAC-benchmark/merged_script/experience_data/\" + \\\n",
    "# \"remote_fundamental/magsac-test/experience_results/{}/fun_{}_std*_ratio*_outputRS.txt\",\n",
    "#     \"/home/clementriu/Documents/these/RANSAC-benchmark/merged_script/experience_data/\" + \\\n",
    "# \"remote_fundamental/magsac-test/experience_results/{}/fun_{}_std*_ratio*_magsacOut.txt\",    \n",
    "# ]\n",
    "# magsac_default_path = \"/home/clementriu/Documents/these/RANSAC-benchmark/merged_script/experience_data/\" + \\\n",
    "# \"remote_fundamental/magsac-test/experience_results/uniform/fun_{}_std*_ratio*_magsac{}.txt\"\n",
    "\n",
    "\n",
    "# other_editable_glob_to_results = [\n",
    "#     \"/home/riuclement//Documents/RANSAC-benchmark/3dv_experiment/general/essential/2021_06_13_11_25_09/\" +\\\n",
    "#     \"experiment_results/{}/ess_{}_std*_ratio*_output.txt\",\n",
    "#     \"/home/riuclement//Documents/RANSAC-benchmark/3dv_experiment/general/essential/2021_06_13_11_25_09/\" +\\\n",
    "#     \"experiment_results/{}/ess_{}_std*_ratio*_magsacOut.txt\",    \n",
    "# ]\n",
    "# magsac_default_path = \"/home/riuclement//Documents/RANSAC-benchmark/3dv_experiment/general/essential/2021_06_13_11_25_09/\" +\\\n",
    "#     \"experiment_results/uniform/ess_{}_std*_ratio*_magsac{}.txt\"\n",
    "\n",
    "folder_names = ['uniform']\n",
    "data_numbers = [11]\n",
    "noise_stds = [float(i / 10) for i in range(31)]\n",
    "# noise_stds = [float(i / 5) for i in range(16)]\n",
    "outlier_ratios = [float(i / 10) for i in range(10)]\n",
    "\n",
    "file_names = [\"Weights\", \"Labels\", \"Errors\", \"ErrorsAll\", \"Inliers\", \"PosInl\"]\n",
    "file_types = [\"float\", \"int\", \"float\", \"float\", \"int\", \"int\"]\n",
    "\n",
    "other_algorithms = [\"Ransac-3\", \"Ransac-9\", \"AC-Ransac\", \"LRT\"]\n",
    "time_algorithms = [\"Magsac\"]\n",
    "magsac_algorithms = ['Magsac-True-Threshold', \n",
    "                     'Magsac-AC-Ransac-Threshold', \n",
    "                     'Magsac-P', \n",
    "                     'Magsac-R',\n",
    "                     'Magsac-W']\n",
    "\n",
    "# model_type = \"homography - USAC\"\n",
    "# model_type = \"homography - Homogr\"\n",
    "model_type = \"fundamental matrix - KUSVOD2\"\n",
    "# model_type = \"fundamental matrix - USAC\"\n",
    "# model_type = \"fundamental matrix - Multi H\"\n",
    "# model_type = \"essential matrix - USAC\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "raised-johns",
   "metadata": {},
   "outputs": [],
   "source": [
    "# other_editable_glob_to_results2 = [\n",
    "#     default_path + \"experiment_results/{}/hom_{}_std*_ratio*_MUSEOutput.txt\",\n",
    "#     default_path + \"experiment_results/{}/hom_{}_std*_ratio*_magsacOut.txt\",    \n",
    "# ]\n",
    "# magsac_default_path2 = default_path + \"experiment_results/uniform/hom_{}_std*_ratio*_magsac{}.txt\"\n",
    "\n",
    "other_editable_glob_to_results2 = [\n",
    "    default_path + \"experiment_results/{}/fun_{}_std*_ratio*_MUSEOutput.txt\",\n",
    "    default_path + \"experiment_results/{}/fun_{}_std*_ratio*_magsacOut.txt\",    \n",
    "]\n",
    "magsac_default_path2 = default_path + \"experiment_results/uniform/fun_{}_std*_ratio*_magsac{}.txt\"\n",
    "\n",
    "# other_editable_glob_to_results2 = [\n",
    "#     default_path + \"experiment_results/{}/ess_{}_std*_ratio*_MUSEOutput.txt\",\n",
    "#     default_path + \"experiment_results/{}/ess_{}_std*_ratio*_magsacOut.txt\",    \n",
    "# ]\n",
    "# magsac_default_path2 = default_path + \"experiment_results/uniform/ess_{}_std*_ratio*_magsac{}.txt\"\n",
    "\n",
    "other_algorithms2 = [\"MUSE\", 'a', \"AC-Ransac\", \"b\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "human-ecuador",
   "metadata": {},
   "outputs": [],
   "source": [
    "# other_editable_glob_to_results3 = [\n",
    "#     default_path + \"experiment_results/{}/hom_{}_std*_ratio*_FastACOutput.txt\",\n",
    "#     default_path + \"experiment_results/{}/hom_{}_std*_ratio*_magsacOut.txt\",    \n",
    "# ]\n",
    "# magsac_default_path3 = default_path + \"experiment_results/uniform/hom_{}_std*_ratio*_magsac{}.txt\"\n",
    "\n",
    "other_editable_glob_to_results3 = [\n",
    "    default_path + \"experiment_results/{}/fun_{}_std*_ratio*_FastACOutput.txt\",\n",
    "    default_path + \"experiment_results/{}/fun_{}_std*_ratio*_magsacOut.txt\",    \n",
    "]\n",
    "magsac_default_path3 = default_path + \"experiment_results/uniform/fun_{}_std*_ratio*_magsac{}.txt\"\n",
    "\n",
    "# other_editable_glob_to_results3 = [\n",
    "#     default_path + \"experiment_results/{}/ess_{}_std*_ratio*_FastACOutput.txt\",\n",
    "#     default_path + \"experiment_results/{}/ess_{}_std*_ratio*_magsacOut.txt\",    \n",
    "# ]\n",
    "# magsac_default_path3 = default_path + \"experiment_results/uniform/ess_{}_std*_ratio*_magsac{}.txt\"\n",
    "\n",
    "other_algorithms3 = [\"Fast-AC-RanSac\", 'a', \"AC-Ransac\", \"b\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "passing-diploma",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_format = \".pdf\"\n",
    "# file_format = \".png\"\n",
    "# save_name =\"/home/clementriu/Documents/these/RANSAC-benchmark/merged_script/experience_data/\" + \\\n",
    "# \"remote_homography/magsac_test/experience_results/{}_{}_the{}\".format(data_numbers[0], \"{}\", file_format)\n",
    "save_name = default_path +  \"{}_{}_the{}\".format(data_numbers[0], \"{}\", file_format)\n",
    "# save_name =\"/home/clementriu/Documents/these/RANSAC-benchmark/merged_script/experience_data/\" + \\\n",
    "# \"remote_essential/2021_01_09_01_38_02/experience_results/{}_{}_the{}\".format(data_numbers[0], \"{}\", file_format)\n",
    "\n",
    "remove = ['Magsac-True-Threshold',\n",
    "          'Magsac-AC-Ransac-Threshold'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "desperate-regular",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = All_Data_Loader(other_editable_glob_to_results,\n",
    "                              magsac_default_path,\n",
    "                              folder_names,\n",
    "                              data_numbers,\n",
    "                              noise_stds,\n",
    "                              outlier_ratios,\n",
    "                              file_names,\n",
    "                              file_types,\n",
    "                              other_algorithms,\n",
    "                              time_algorithms,\n",
    "                              magsac_algorithms,\n",
    "                              model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "maritime-hughes",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader.create_paths()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fluid-notebook",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optional-senate",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader.get_metrics(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "saved-science",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader.create_summary(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "raised-clinton",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader.concatenate_all_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incredible-monthly",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader.generate_f1score(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convertible-incentive",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader2 = All_Data_Loader(other_editable_glob_to_results2,\n",
    "                              magsac_default_path2,\n",
    "                              folder_names,\n",
    "                              data_numbers,\n",
    "                              noise_stds,\n",
    "                              outlier_ratios,\n",
    "                              file_names,\n",
    "                              file_types,\n",
    "                              other_algorithms2,\n",
    "                              time_algorithms,\n",
    "                              magsac_algorithms,\n",
    "                              model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arranged-military",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader2.create_paths()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "driving-flash",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader2.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proud-trial",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader2.get_metrics(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "immune-process",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader2.create_summary(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prime-removal",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader2.concatenate_all_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "certain-species",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader2.generate_f1score(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imperial-frederick",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader3 = All_Data_Loader(other_editable_glob_to_results3,\n",
    "                              magsac_default_path3,\n",
    "                              folder_names,\n",
    "                              data_numbers,\n",
    "                              noise_stds,\n",
    "                              outlier_ratios,\n",
    "                              file_names,\n",
    "                              file_types,\n",
    "                              other_algorithms3,\n",
    "                              time_algorithms,\n",
    "                              magsac_algorithms,\n",
    "                              model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pending-boards",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader3.create_paths()\n",
    "data_loader3.load_data()\n",
    "data_loader3.get_metrics(0.1)\n",
    "data_loader3.create_summary(0.1)\n",
    "data_loader3.concatenate_all_data()\n",
    "data_loader3.generate_f1score(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civil-import",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove2 = [\n",
    "    'AC-Ransac',\n",
    "    'b',\n",
    "    'Magsac-True-Threshold',\n",
    "    'Magsac-AC-Ransac-Threshold',\n",
    "    'Magsac-P',\n",
    "    'Magsac-R',\n",
    "    'Magsac-W',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "former-spine",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_mean_addition = data_loader._time_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prostate-gospel",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_mean_addition[folder_names[0]][data_numbers[0]][\"MUSE\"] = data_loader2._time_mean[folder_names[0]][data_numbers[0]][\"MUSE\"]\n",
    "time_mean_addition[folder_names[0]][data_numbers[0]][\"Fast-AC-Ransac\"] = data_loader3._time_mean[folder_names[0]][data_numbers[0]][\"Fast-AC-RanSac\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "guilty-monroe",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_algorithms_addition = data_loader._all_time_algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controversial-destruction",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_algorithms_addition += ['Fast-AC-Ransac', 'MUSE']\n",
    "# all_algorithms_addition += ['MUSE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alternate-temperature",
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_ratio = 0.8\n",
    "outlier_ratio_index = int(outlier_ratio * 10)\n",
    "data_loader.generate_single_image(folder_names[0],\n",
    "                                  data_numbers[0],\n",
    "                                  all_algorithms_addition,\n",
    "                                  remove,\n",
    "                                  outlier_ratio,\n",
    "                                  outlier_ratio_index,\n",
    "                                  \"Runtime (s)\",\n",
    "                                  time_mean_addition,\n",
    "                                  data_loader._f1score_std,\n",
    "                                  std_=False,\n",
    "                                  save_=save_name.format(\"FastMUSE_runtime_{}_\".format(outlier_ratio)),\n",
    "#                                   threshold_=.495\n",
    "                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aerial-frederick",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1score_addition = data_loader._f1score_mean\n",
    "precision_mean_addition = data_loader._precision_mean\n",
    "recall_mean_addition = data_loader._recall_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "behind-western",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1score_addition[folder_names[0]][data_numbers[0]][\"MUSE\"] = data_loader2._f1score_mean[folder_names[0]][data_numbers[0]][\"MUSE\"]\n",
    "precision_mean_addition[folder_names[0]][data_numbers[0]][\"MUSE\"] = data_loader2._precision_mean[folder_names[0]][data_numbers[0]][\"MUSE\"]\n",
    "recall_mean_addition[folder_names[0]][data_numbers[0]][\"MUSE\"] = data_loader2._recall_mean[folder_names[0]][data_numbers[0]][\"MUSE\"]\n",
    "\n",
    "f1score_addition[folder_names[0]][data_numbers[0]][\"Fast-AC-Ransac\"] = data_loader3._f1score_mean[folder_names[0]][data_numbers[0]][\"Fast-AC-RanSac\"]\n",
    "precision_mean_addition[folder_names[0]][data_numbers[0]][\"Fast-AC-Ransac\"] = data_loader3._precision_mean[folder_names[0]][data_numbers[0]][\"Fast-AC-RanSac\"]\n",
    "recall_mean_addition[folder_names[0]][data_numbers[0]][\"Fast-AC-Ransac\"] = data_loader3._recall_mean[folder_names[0]][data_numbers[0]][\"Fast-AC-RanSac\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lasting-hometown",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_algorithms_data = data_loader._all_algorithms\n",
    "all_algorithms_data += ['Fast-AC-Ransac','MUSE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "olive-pollution",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader.generate_single_image(folder_names[0],\n",
    "                                  data_numbers[0],\n",
    "                                  all_algorithms_data,\n",
    "                                  remove,\n",
    "                                  outlier_ratio,\n",
    "                                  outlier_ratio_index,\n",
    "                                  \"F1-score\",\n",
    "                                  f1score_addition,\n",
    "                                  data_loader._f1score_std,\n",
    "                                  std_=False,\n",
    "                                  save_=save_name.format(\"FastMUSE_f1score_{}_\".format(outlier_ratio)),\n",
    "                                  threshold_=.495\n",
    "                                 )\n",
    "\n",
    "data_loader.generate_single_image(folder_names[0],\n",
    "                                  data_numbers[0],\n",
    "                                  all_algorithms_data,\n",
    "                                  remove,\n",
    "                                  outlier_ratio,\n",
    "                                  outlier_ratio_index,\n",
    "                                  \"Precision\",\n",
    "                                  precision_mean_addition,\n",
    "                                  data_loader._f1score_std,\n",
    "                                  std_=False,\n",
    "                                  save_=save_name.format(\"FastMUSE_precision_{}_\".format(outlier_ratio)),\n",
    "                                  threshold_=.495\n",
    "                                 )\n",
    "\n",
    "data_loader.generate_single_image(folder_names[0],\n",
    "                                  data_numbers[0],\n",
    "                                  all_algorithms_data,\n",
    "                                  remove,\n",
    "                                  outlier_ratio,\n",
    "                                  outlier_ratio_index,\n",
    "                                  \"Recall\",\n",
    "                                  recall_mean_addition,\n",
    "                                  data_loader._f1score_std,\n",
    "                                  std_=False,\n",
    "                                  save_=save_name.format(\"FastMUSE_recall_{}_\".format(outlier_ratio)),\n",
    "                                  threshold_=.495\n",
    "                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "several-placement",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
