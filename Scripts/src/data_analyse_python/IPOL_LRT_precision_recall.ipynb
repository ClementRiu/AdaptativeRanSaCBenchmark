{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "official-suggestion",
   "metadata": {},
   "source": [
    "## Impact of LRTSAC early bailout on precision and recall\n",
    "\n",
    "File used to create figures 10 and 11 of the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interested-finnish",
   "metadata": {},
   "outputs": [],
   "source": [
    "import single_data_loader\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "composed-williams",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "talented-fortune",
   "metadata": {},
   "source": [
    "Glob path to the output files of the experiment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spoken-drain",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_glob_format = \"/home/riuclement/Documents/RANSAC-benchmark/ipol_experiment/qs_exp/*/experience_results/uniform/{}_{}_std{}_ratio{}_output_lrt.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "understood-begin",
   "metadata": {},
   "source": [
    "Options and default values of the experiment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valuable-intent",
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithms = [\"LRT all options\", \"LRT no bailout\"]\n",
    "num_metrics = 4\n",
    "datasets = {\"hom\": 10, \"fun\": 11, \"ess\": 6}\n",
    "sigma_values = np.arange(0, 3.1, 0.1)\n",
    "ratio_values = np.arange(0, 1, 0.1)\n",
    "num_runs = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "democratic-pleasure",
   "metadata": {},
   "source": [
    "Loading of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "novel-surge",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = single_data_loader.Metric_Data_Loader(\n",
    "    file_glob_format,\n",
    "    algorithms,\n",
    "    num_metrics,\n",
    "    datasets,\n",
    "    sigma_values,\n",
    "    ratio_values,\n",
    "    num_runs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minus-aquarium",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader.load_and_clean_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pointed-nickname",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ticks(datasize):\n",
    "    x_names = [\n",
    "        \"H{}\".format(i) for i in range(1, datasize[\"hom\"] + 1)\n",
    "    ] + [\n",
    "        \"F{}\".format(i) for i in range(1, datasize[\"fun\"] + 1)\n",
    "    ] + [\n",
    "        \"E{}\".format(i) for i in range(1, datasize[\"ess\"] + 1)\n",
    "    ]\n",
    "    x_ticks = [i + 1 for i in range(len(x_names))]\n",
    "    return x_ticks, x_names\n",
    "\n",
    "def plot_allmetrics_LRT(metric_index, metric_name, values, lim=False, save=False):\n",
    "    x_ticks, x_names = create_ticks(values._datasets)\n",
    "    metric_values = []\n",
    "    for dataset_name in sorted(list(values._datasets.keys()), reverse=True):\n",
    "        metric_values.append(values._mean_values[dataset_name][:, metric_index, :, :, :])\n",
    "    metric_values = np.concatenate(metric_values, axis=1)\n",
    "    metric_ratio = metric_values[0, :, :, :] / metric_values[1, :, :, :]\n",
    "    metric_ratio[np.isnan(metric_ratio)] = np.nanmedian(metric_ratio)\n",
    "    \n",
    "    plt.figure(figsize=(10, 3))\n",
    "    plt.title('{} of LRT with bailout over {} of LRT without bailout\\nover all datasets and all settings'.format(metric_name, metric_name))\n",
    "    plt.boxplot(metric_ratio.reshape(-1, metric_ratio.shape[1] * metric_ratio.shape[2]).T,\n",
    "               sym=\"\")\n",
    "    plt.xlabel('Dataset names')\n",
    "    plt.ylabel('{} ratio '.format(metric_name))\n",
    "    plt.xticks(x_ticks, x_names)\n",
    "\n",
    "    if lim:\n",
    "        plt.ylim(0.9, 1.1)\n",
    "    plt.tight_layout()\n",
    "    if save:\n",
    "        plt.savefig(save)\n",
    "    else:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optical-lodge",
   "metadata": {},
   "source": [
    "Plot the precision and recall for LRTSac with and without early bailout:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "likely-reality",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_allmetrics_LRT(0, 'Precision', data_loader, lim=False, save=False)\n",
    "plot_allmetrics_LRT(1, 'Recall', data_loader, lim=True, save=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developmental-motorcycle",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
